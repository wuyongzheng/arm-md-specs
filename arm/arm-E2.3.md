## E2.3 Definition of the memory model

This section describes observation and ordering in the memory model. It contains the following subsections:

- Basic and dependency definitions.
- Ordering relations and constraints.
- Ordering of instruction fetches.
- Restrictions on the effects of speculation.
- Memory barriers.

For more information on endpoint ordering of memory accesses, see Reordering.

In the memory model, the Shareability memory attribute indicates the degree to which hardware must ensure memory coherency between a set of observers, see Memory types and attributes.

The architecture defines additional memory attributes and associated behaviors, which are defined in the system level section of this manual. See:

- The AArch32 System Level Memory Model.
- The AArch32 Virtual Memory System Architecture.

See also Mismatched memory attributes.

## E2.3.1 Basic and dependency definitions

The memory model provides a set of definitions that are used to construct conditions on the permitted sequences of accesses to memory. See Ordering requirements defined by the formal concurrency model for more information.

## E2.3.2 Ordering relations and constraints

See Ordering requirements defined by the formal concurrency model for more information.

## E2.3.3 Ordering of instruction fetches

For two memory locations A and B, if A has been written to with an updated value and been made coherent with the instruction fetches of the shareability domain before B has been written to with an updated value by an observer in the same shareability domain, then where, for an observer in the shareability domain, an instruction read from B appears in program order before an instruction fetched from A, if the instruction read from B contains the updated value of B then the instruction read from A appearing later in program order will contain the updated value of A.

Awrite has been made coherent with an instruction fetch of a shareability domain when:

- CTR.{DIC, IDC} == {0, 0} The location written to has been cleaned to the Point of unification (PoU) from the data cache, and that clean is complete for the shareability domain. Subsequently the location has been invalidated to the Point of unification (PoU) from the instruction cache, and that invalidation is complete for the shareability domain.
- CTR.{DIC, IDC} == {0, 1} The write is complete for the shareability domain. Subsequently the location has been invalidated to the Point of unification (PoU) from the instruction cache, and that invalidation is complete for the shareability domain.
- CTR.{DIC, IDC} == {1, 1} The write is complete for the shareability domain.

Note

Microarchitecturally, this means that these situations cannot both be true in an implementation:

- After delays in fetching from memory, the instruction queue can have entries written into it out of order.

- For an implementation:

- When CTR.DIC == 0, if there is an outstanding entry in the instruction queue, then later entries in the instruction queue are not impacted by the ICIMV AU instructions of a different core.

- WhenCTR.DIC==1,ifthereis a write to the location that is held in the queue when there is an outstanding entry in the instruction queue for an older entry, then the instruction queue does not have entries invalidated from it.

## E2.3.4 AArch32 restrictions on the effects of speculation

The Arm architecture places certain restrictions on the effects of speculation. These are:

- Each load from a location using a particular V A after an exception return that is a Context Synchronization event will not speculatively read an entry from earlier in the coherence order for the location being loaded from than the entry generated by the latest store to that location using the same V A before the exception exit.
- Each load from a location using a particular V A after an exception entry that is a Context Synchronization event will not speculatively read an entry from earlier in the coherence order for the location being loaded from than the entry generated by the latest store to that location using the same V A before the exception entry.
- Any load from a location using a particular V A before an exception entry that is a Context Synchronization event will not speculatively read data from a store to the same location using the same V A after the exception entry.
- Any load from a location using a particular V A before an exception return that is a Context Synchronization event will not speculatively read data from a store to the same location using the same V A after the exception exit.
- When data is loaded under speculation with a Translation fault, it cannot be used to form an address or generate condition codes to be used by other instructions in the speculative sequence.
- When data is loaded under speculation from a location that does not have a valid translation for the translation regime being speculated in, the data cannot be used to form an address or generate condition codes to be used by other instructions in the speculative sequence.
- When data is loaded as a result of speculative accesses made after TLBI + DSB + ERET using a translation that was invalidated by the TLBI, the data cannot be used to form an address, generate condition codes, or generate SVE predicate values to be used by other instructions in the speculative sequence. The execution timing of any other instructions in the speculative sequence is not a function of the data loaded.
- Changes to System registers must not occur speculatively in a way that can affect a speculative memory access that can cause a change to the microarchitectural state.
- Changes to Special-purpose registers can occur speculatively.
- Execute-never controls apply to speculative instruction fetching. See Access permissions for instruction execution.
- When writing new instructions to memory, there is no requirement for an SB instruction to prevent speculative execution of the old code. See Instruction cache maintenance instructions.

Note

The prohibition of using data loaded under speculation with faults to form addresses, condition codes or SVE predicate values does not prohibit the use of value predicted data from such locations for such purposes, so long as the training of the data value prediction was from the hardware defined context that is using the prediction. A consequence of this is that training of value prediction cannot be based on data loaded under speculation with a translation or Permission fault.

## E2.3.4.1 AArch32 Speculative Store Bypass Safe

When FEAT\_SSBS is implemented, CPSR.SSBS is a control that can be set by software to indicate whether hardware is use, in a manner that is potentially speculatively exploitable, a speculative value in a register that has been loaded from memory using a load instruction that speculatively read an entry for the location being loaded from, where the entry that

is speculatively read is from earlier in the coherence order than the entry generated by the latest store to that location using the same virtual address as the load instruction.

Aspeculative value in a register is used in a potentially speculatively exploitable manner if it is used to form an address, generate condition codes, or generate SVE predicate values to be used by other instructions in the speculative sequence or if the execution timing of any other instructions in the speculative sequence is a function of the data loaded under speculation.

When the value of CPSR.SSBS is 0, hardware is not permitted to use speculative register values in a potentially speculatively exploitable manner if the speculative read that loads the register is from earlier in the coherence order than the entry generated by the latest store to that location using the same virtual address as the load instruction.

When the value of CPSR.SSBS is 1, hardware is permitted to use speculative register values in a potentially speculatively exploitable manner if the speculative read that loads the register is from earlier in the coherence order than the entry generated by the latest store to that location using the same virtual address as the load instruction.

Note

- If speculation is permitted, then cache timing side channels can lead to addresses being derived using reads of address values that have been speculatively loaded from memory to a register.
- Before the introduction of FEAT\_SSBS, the control bit SPSR.SSBS was RES0, and therefore software written without awareness of FEAT\_SSBS is expected to program it to 0. This means that CPSR.SSBS will not be set, so the PE will not be permitted to use speculative loads with outstanding memory disambiguation issues for any subsequent speculative memory accesses if there is any possibility of those subsequent memory accesses creating a cache timing side channel.

## E2.3.4.2 Definition of exploitative control of speculative execution

The execution of some code (code1) can exploitatively control speculative execution of some other code (code2) if and only if all of the following apply:

- The actions of code1 can influence, in a manner that is not hard-to-determine, the prediction of multi-bit values that determine speculative execution of code2 to cause an irreversible change to the microarchitectural state of the PE that is indicative of some architectural state accessible to the execution context of code2.
- code1 has control in determining the choice of the architectural state that the irreversible change to the microarchitectural state is indicative of.
- The irreversible changes to the microarchitectural state of the PE can be measured by code executing in an execution context other than that of code2 to allow the retrieval of the architectural state in a computationally feasible manner that is not hard-to-determine.

## E2.3.4.3 Definition of predictive leakage to speculative execution

The execution of some code (code1) can predictively leak to some other code (code2) if and only if all of the following apply:

- The execution of code1 influences, in a manner that is not hard-to-determine, the predictive microarchitectural structures of the implementation that predict multi-bit values, not binary choices, to behave in a way that is indicative of some architectural state accessible to the execution context of code1.
- The predictive microarchitectural structures of the implementation impact the timing of the speculative execution of code2 in a way that enables code2 to recover the architectural state in a manner that is not hard-to-determine.
- code1 and code2 are not collaborating to communicate using the mechanisms in the previous two bullets.

Note

Mechanisms to prevent the influence and the state recovery being 'not hard-to-determine' are left open to implementations. Examples could include the complete separation of prediction resources, or the isolation of the predictions using a cryptographic or pseudo-random mechanism to separate each context.

## E2.3.4.4 Further restrictions on the effects of speculation from Armv8.5

Further restrictions on speculation are introduced by some additional architectural features as described here.

FEAT\_CSV3 introduces these restrictions:

- An attempt to access data under speculation, where the data is inaccessible given the current state of the PE cannot be used to alter the architectural or microarchitectural state in a manner that allows the value of the inaccessible data to be recovered by code architecturally executed through means such as measuring the timing of code. This restriction applies to any of the following cases which make the data inaccessible:

- [ ] - reading from a Location with a Permission or Domain fault.

- [ ] - directly reading from a system register that is not architecturally readable.

- [ ] - reading from a SIMD&amp;FP register that is not accessible due to traps configured by a more privileged Exception level.

- [ ] - indirectly reading from a system register containing a Pointer Authentication Key for which the corresponding Pointer Authentication instructions are disabled.

- [ ] Note

The current state of the PE is defined as the EL, values of all special-purpose registers, and values of all system registers under which the hardware attempts to access the data, which may be on the speculative execution path. If on the speculative execution path, the hardware must respect any changes to the PE state that occur on the speculative path, respecting the same rules that would be required if executing on the non-speculative path.

Note

The following is a list of examples in which use of the inaccessible data could lead to recovery of the value of the inaccessible data:

- [ ] - to form an address or generate condition codes to be used in the speculative sequence.

- [ ] - to form the register value used for the comparison of a compare-and-branch, test-and-branch, or compare- and-swap instruction in the speculative sequence. Note that this is to cover conditional instructions that do not use condition codes to determine their outcomes.

- [ ] - by prediction mechanisms such as Cache Prefetch or Data Value predictions.

- [ ] - as an input to an instruction in the speculative sequence where the execution timing of the instruction is dependent on the data value.

Note

It is permissible for a value of zero to be produced by the load or register read and consumed by an instruction newer than the load in the speculative sequence even if the value of zero results in different execution timing compared to non-zero values.

Note

As the effects of speculation are not architecturally visible, this restriction level requires that the effect of any speculation cannot give rise to side channels that will leak the values of memory locations, System registers, or Special-purpose registers to a level of privilege that would otherwise not be able to determine those values.

- Changes to System registers must not occur speculatively in a way that can affect a speculative memory access that can cause a change to the microarchitectural state.

Note

Changes to Special-purpose registers can occur speculatively.

FEAT\_CSV2 and FEAT\_CSV2\_1p1 introduce a range of additional restrictions:

If FEAT\_CSV2 is implemented:

- Code running in one hardware-defined context (context1) cannot either exploitatively control, or predictively leak to, the speculative execution of code in a different hardware-defined context (context2), as a result of the behavior of any of the following resources:

- [ ] - Branch target prediction based on the branch targets used in context1.

- [ ] - This applies to both direct and indirect branches, including return instructions, but excludes the prediction of the direction of a conditional branch.

- Data Value predictions based on data value from execution in context1.

Note

The prediction of the PSTATE.{N,Z,C,V} values is not considered a data value for this purpose.

- Virtual address-based cache prefetch predictions generated as a result of execution in context1.

- Any other prediction mechanisms, other than Branch, Data Value, or Cache Prefetch predictions. In this definition, the hardware-defined context is determined by:

- The Exception level.

- The Security state.

- When executing at EL1, if EL2 is implemented and enabled in the current Security state, the VMID.

- When executing at EL0, whether the EL1&amp;0 or the EL2&amp;0 translation regime is in use.

- When executing at EL0 and using the EL1&amp;0 translation regime, the ASID and, if EL2 is implemented and enabled in the current Security state, the VMID.

- When executing at EL0 and using the EL2&amp;0 translation regime, the ASID.

If FEAT\_CSV2\_1p1 is implemented:

- Code running in one hardware-defined context (context1) cannot either exploitatively control, or predictively leak to, the speculative execution of code in a different hardware-defined context (context2) as a result of the behavior of branch target prediction based on the branch history used in context1.
- Branch or data values trained from one instruction address cannot exploitatively control, or predictively leak to, the speculative execution of code from a different address.

## E2.3.5 Memory barriers

The Arm architecture is a weakly ordered memory architecture that supports out of order completion. Memory barrier is the general term applied to an instruction, or sequence of instructions, that forces synchronization events by a PE with respect to retiring load/store instructions. The memory barriers defined by the architecture provide a range of functionality, including:

- Ordering of load/store instructions.
- Completion of load/store instructions.
- Context synchronization.

The following subsections describe the memory barrier instructions:

- Instruction Synchronization Barrier.
- Data Memory Barrier.
- Data Synchronization Barrier.
- Speculation Barrier.
- Consumption of Speculative Data Barrier.
- Speculative Store Bypass Barrier.
- Physical Speculative Store Bypass Barrier.
- Trace Synchronization Barrier.
- Shareability and access limitations on the data barrier operations.
- Load-Acquire, Store-Release.

Note

Depending on the required synchronization, a program might use memory barriers on their own, or it might use them in conjunction with cache maintenance and memory management instructions that in general are available only when software execution is at EL1 or higher.

The DMB and DSB memory barriers affect reads and writes to the memory system generated by load/store instructions and data or unified cache maintenance instructions being executed by the PE.

AArch32 state also supports the legacy barrier instructions CP15DMB, CP15DSB, and CP15ISB. These instructions are executed as MCR s using the appropriate encoding, and are accessible from EL0. However, for performance reasons Arm deprecates any use of these operations, and strongly recommends that software uses the DMB , DSB , and ISB instructions

described in this section instead. Optionally, an implementation can support a CP15BEN control that supervisory software can use to disable use of these instructions, meaning the corresponding MCR encodings are UNDEFINED. When the CP15BEN control is supported, setting one of the following CP15BEN fields to 0 makes execution of CP15DMB, CP15DSB, and CP15ISB UNDEFINED:

- SCTLR\_EL1.CP15BEN, for execution of these instructions at EL0 using AArch32 when EL1 is using AArch64.
- SCTLR.CP15BEN, for execution of these instructions at EL0 or EL1 when EL1 is using AArch32.
- HSCTLR.CP15BEN, for execution of these instructions at EL2 when EL2 is using AArch32.

## E2.3.5.1 Instruction Synchronization Barrier

An ISB instruction ensures that all instructions that come after the ISB instruction in program order are fetched from the cache or memory after the ISB instruction has completed. Using an ISB ensures that the effects of context-changing operations executed before the ISB are visible to the instructions fetched after the ISB instruction. Examples of context-changing operations that require the insertion of an ISB instruction to ensure the effects of the operation are visible to instructions fetched after the ISB instruction are:

- Completed cache and TLB maintenance instructions.
- Changes to System registers.

Any context-changing operations appearing in program order after the ISB instruction take effect only after the ISB has been executed.

The pseudocode function for the operation of an ISB is InstructionSynchronizationBarrier() .

See also Memory barriers.

## E2.3.5.2 Data Memory Barrier

The DMB instruction is a memory barrier instruction that ensures the relative order of memory accesses before the barrier with memory accesses after the barrier. The DMB instruction does not ensure the completion of any of the memory accesses for which it ensures relative order.

The full definition of the DMB instruction is covered formally in the Definition of the memory model and this introduction to the DMB instruction is not intended to contradict that section.

The basic principle of a DMB instruction is to introduce order between memory accesses that are specified to be affected by the DMB options supplied as arguments to the DMB instruction. The DMB instruction ensures that all affected memory accesses by the PE executing the DMB instruction that appear in program order before the DMB instruction and those which originate from a different PE, to the extent required by the DMB options, which have been Observed-by the PE before the DMB instruction is executed, are Observed-by each PE, to the extent required by the DMB options, before any affected memory accesses that appear in program order after the DMB instruction are Observed-by that PE.

The use of a DMB instruction creates order between the Memory effects of instructions as described in the definition of Barrier-ordered-before.

The pseudocode function for the operation of a DMB instruction is DataMemoryBarrier() .

## E2.3.5.3 Data Synchronization Barrier

A DSB instruction is a memory barrier that ensures that memory accesses that occur before the DSB instruction have completed before the completion of the DSB instruction. In doing this, it acts as a stronger barrier than a DMB and all ordering that is created by a DMB with specific options is also generated by a DSB with the same options.

Execution of a DSB at EL2 ensures that any memory accesses caused by speculative translation table walks from the Non-secure PL1&amp;0 translation regime have been observed.

For more information, see Use of out-of-context translation regimes.

A DSB executed by a PE, PEe, completes when all of the following apply:

- All explicit memory effects of the required access types appearing in program order before the DSB are complete for the set of observers in the required shareability domain.
- If the required access types of the DSB is reads and writes, the following instructions issued by PEe before the DSB are complete for the required shareability domain:

- [ ] - All cache maintenance instructions.

- [ ] - All AArch32 TLB maintenance instructions.

- [ ] - All PSB instructions.

- If the required access types of the DSB is reads and writes, completion of a DSB instruction executed by PEe ensures that:

- [ ] - All previous TLB maintenance operations generated by AArch32 TLB maintenance instructions executed at EL1 by PEe when HCRX\_EL2.FnXS is 1 are finished for all PEs in the shareability domain of the DSB instruction.

- [ ] - All previous TLB maintenance operations generated by AArch32 TLB maintenance instructions are finished for all PEs in the shareability domain of the DSB instruction.

In addition, no instruction that appears in program order after the DSB instruction can alter any state of the system or perform any part of its functionality until the DSB completes, other than:

- Being fetched from memory and decoded, or any change to architectural or microarchitectural state resulting from being fetched or decoded.

- Indirectly or directly reading any of the following, so long as the reading of these resources does not cause a change in architectural state:

- General-purpose registers

- SIMD&amp;FP registers

- The Stack Pointer register

- The Program Counter

- [ ] - Special-purpose registers

- If FEAT\_ETS2 is not implemented, having any virtual addresses of loads and stores translated.

The pseudocode function for the operation of a DSB is DataSynchronizationBarrier() .

See also Memory barrier instructions and Memory barriers.

## E2.3.5.4 Speculation Barrier

An SB instruction is a memory barrier that prevents speculative execution of instructions until after the barrier has completed.

Until the barrier completes, the speculative execution of any instruction appearing later in the program order than the barrier cannot be performed to the extent that such speculation can be observed through side-channels as a result of control flow speculation or data value speculation. An example is speculative allocation into any caching structure where the allocation of that entry could indicate data value present in memory or in the registers.

The speculative execution of an SB instruction cannot be as a result of any of the following:

- Control flow speculation.

- Data value speculation.

An SB instruction can complete when all of the following apply:

- It is known that it is not speculative, or it is speculative only as a result of either:

- [ ] - Speculating that an instruction that could generate an exception does not generate an exception.

- [ ] - Speculating past the point in the Execution stream where a precise asynchronous exception is taken.

- All the predicted data values generated by instructions appearing in program order before the SB instruction are architecturally resolved, and so are not speculative.

Note

The SB instruction has no effect on the use of prediction resources to predict the instruction stream that is being fetched, so long as the prediction of the instruction stream is not informed by data taken from the register outputs of the speculative execution of instructions appearing in program order after an uncompleted SB instruction.

## E2.3.5.5 Consumption of Speculative Data Barrier

The CSDB instruction is a memory barrier instruction that controls speculative execution arising from data value prediction.

Any instruction, other than a branch instruction, that appears in program order after the CSDB cannot be speculatively executed using the results of any of the following predictions if those predictions come from instructions that appear in program order before the CSDB and have not been architecturally resolved:

- Data value predictions of any instructions.
- PSTATE.{N,Z,C,V} predictions of any instructions other than conditional branch instructions or conditional instructions that write to the PC.

Note

For purposes of the definition of CSDB, PSTATE.{N,Z,C,V} are not considered data values. This definition permits:

- Control flow speculation before and after the CSDB instruction.
- Speculative execution of conditional data processing instructions after the CSDB instruction, unless they use the results of data value or PSTATE.{N,Z,C,V} predictions of instructions appearing in program order before the CSDB instruction that have not been architecturally resolved.

## E2.3.5.6 Speculative Store Bypass Barrier

The SSBB instruction is a memory barrier that prevents speculative loads from bypassing earlier stores to the same virtual address under certain conditions.

The semantics of the Speculative Store Bypass Barrier are:

- When a load to a location appears in program order after the SSBB , then the load does not speculatively read an entry earlier in the coherence order for that location than the entry generated by the latest store satisfying all of the following conditions:
- -The store is to the same location as the load.
- -The store uses the same virtual address as the load.
- -The store appears in program order before the SSBB instruction.
- When a load to a location appears in program order before the SSBB , then the load does not speculatively read data from any store satisfying all of the following conditions:
- -The store is to the same location as the load.
- -The store uses the same virtual address as the load.
- -The store appears in program order after the SSBB instruction.

## E2.3.5.7 Physical Speculative Store Bypass Barrier

The PSSBB instruction is a memory barrier that prevents speculative loads from bypassing earlier stores to the same physical address under certain conditions.

The semantics of the Speculative Store Bypass Barrier are:

- When a load to a location appears in program order after the PSSBB , then the load does not speculatively read an entry earlier in the coherence order for that location than the entry generated by the latest store satisfying all of the following conditions:
- -The store is to the same location as the load.
- -The store appears in program order before the PSSBB instruction.
- When a load to a location appears in program order before the PSSBB , then the load does not speculatively read data from any store satisfying all of the following conditions:
- -The store is to the same location as the load.
- -The store appears in program order after the PSSBB instruction.

Note

The effect of this barrier applies to accesses to the same location even if they are accessed with different virtual addresses and from different Exception levels.

## E2.3.5.8 Trace Synchronization Barrier

The TSB instruction is a barrier instruction that preserves the relative order of accesses to System registers due to trace operations and other accesses to the same registers.

Atrace operation is an operation of the trace unit generating trace for an instruction when FEAT\_TRF is implemented and enabled.

A TSB is not required to execute in program order with respect to other instructions. This includes being reordered with respect to other trace instructions. One or more Context synchronization events are required to ensure that TSB is executed in the necessary order.

If trace is generated between a Context synchronization event and a TSB operation, these trace operations may be reordered with respect to the TSB operation, and therefore may not be synchronized.

The following situations are synchronized using a TSB :

- Adirect write B to a System register is ordered after an indirect read or indirect write of the same register by a trace operation of a traced instruction A, if all of the following are true:
- -Ais executed in program order before a Context synchronization event C.
- -Cis in program order before a TSB operation T.
- -Bis executed in program order after T.
- Adirect read B of a System register is ordered after an indirect write to the same register by a trace operation of a traced instruction A if all the following are true:
- -Ais executed in program order before a Context synchronization event C1.
- -C1 is in program order before TSB operation T.
- -T is executed in program order before a second Context synchronization event C2.
- -Bis executed in program order after C2.

A TSB is not needed when a direct write B to a System register is ordered before an indirect read or indirect write of the same register by a trace operation of a traced instruction A, if all the following are true:

- Ais executed in program order after a Context synchronization event C.
- Bis executed in program order before C.

The pseudocode function for the operation of a TSB is TraceSynchronizationBarrier() .

## E2.3.5.9 Shareability and access limitations on the data barrier operations

The DMB and DSB instructions can each take an optional limitation argument that specifies:

- The shareability domain over which the instruction must operate. This is one of:

- Full system.

- Outer Shareable.

- Inner Shareable.

- Non-shareable.

Full system applies to all the observers in the system and, as such, encompasses the Inner and Outer Shareable domains of the processor.

Note

The distinction between Full system and Outer Shareable is applicable only for Normal Non-cacheable memory accesses and Device memory accesses.

- The accesses for which the instruction operates. This is one of:

- Read and write accesses, both before and after the barrier instruction.

- Write accesses only, before and after the barrier instruction.

- Read accesses before the barrier instruction, and read and write accesses after the barrier instruction.

Note

This form of a DMB or DSB instruction can be described as a load-load/store barrier.

For more information on whether an access is before or after a barrier instruction, see Data Memory Barrier or Data Synchronization Barrier.

Table E2-1 shows how these options are encoded in the &lt;option&gt; field of the instruction.

Table E2-1 Encoding of the DMB and DSB &lt;option&gt; parameter

| Accesses           |                   | Shareability domain   | Shareability domain   |                 |               |
|--------------------|-------------------|-----------------------|-----------------------|-----------------|---------------|
| Before the barrier | After the barrier | Full system           | Outer Shareable       | Inner Shareable | Non-shareable |
| Reads and writes   | Reads and writes  | SY                    | OSH                   | ISH             | NSH           |
| Writes             | Writes            | ST                    | OSHST                 | ISHST           | NSHST         |
| Reads              | Reads and writes  | LD                    | OSHLD                 | ISHLD           | NSHLD         |

If no &lt;option&gt; is specified then the instruction operates for read and write accesses, over the full system, meaning the operation is the same as for the SY option. See the instruction descriptions for more information:

- DMB.
- DSB.

Note

ISB also supports an optional limitation argument that can contain only one value that corresponds to full system operation, see ISB.

## E2.3.5.10 Load-Acquire, Store-Release

The architecture provides a set of instructions with Acquire semantics for loads, and Release semantics for stores.

The full definition of the Load-Acquire instruction is covered formally in the Definition of the memory model and this introduction to the Load-Acquire instruction is not intended to contradict that section.

The basic principle of a Load-Acquire instruction is to introduce order between the memory access generated by the Load-Acquire instruction and the memory accesses appearing in program order after the Load-Acquire instruction, such that the memory access generated by the Load-Acquire instruction is Observed-by each PE, to the extent that PE is required to observe the access coherently, before any of the memory accesses appearing in program order after the Load-Acquire instruction are Observed-by that PE, to the extent that the PE is required to observe the accesses coherently.

The use of a Load-Acquire instruction creates order between the Memory effects of instructions as described in the definition of Barrier-ordered-before.

The full definition of the Store-Release instruction is covered formally in the Definition of the memory model and this introduction to the Store-Release instruction is not intended to contradict that section.

The basic principle of a Store-Release instruction is to introduce order between the memory accesses generated by the PEe executing the Store-Release instruction, together with those which originate from a different PE, to the extent that the PEe is required to observe them coherently, Observed-by the PEe before executing the Store-release.

The use of a Store-Release instruction creates order between the Memory effects of instructions as described in the definition of Barrier-ordered-before.

In addition, the use of a Load-Acquire or a Store-Release instruction on accesses to a Memory-mapped peripheral introduces order between the Memory effects of the instructions that access that peripheral, as described in the definition of Peripheral arrival order.

Load-Acquire and Store-Release, other than LDAEXD and STLEXD , access only a single data element. This access is single-copy atomic. The address of the data object must be aligned to the size of the data element being accessed, otherwise the access generates an Alignment fault.

LDAEXD and STLEXD access two data elements. The address supplied to the instructions must be doubleword-aligned, otherwise the access generates an Alignment fault.

AStore-Release Exclusive instruction has the release semantics only if the store is successful.

Note

- Each Load-Acquire Exclusive and Store-Release Exclusive instruction is essentially a variant of the equivalent Load-Exclusive or Store-Exclusive instruction. All usage restrictions and single-copy atomicity properties:
- -That apply to the Load-Exclusive instructions also apply to the Load-Acquire Exclusive instructions.
- -That apply to the Store-Exclusive instructions also apply to the Store-Release Exclusive instructions.
- The Load-Acquire/Store-Release instructions can remove the requirement to use the explicit DMB memory barrier instruction.

Table E2-2 summarizes the Load-Acquire/Store-release instructions.

Table E2-2 Load-Acquire/Store-Release instructions

| Data type         | Load-Acquire   | Store-Release   | Load-Acquire Exclusive   | Store-Release Exclusive   |
|-------------------|----------------|-----------------|--------------------------|---------------------------|
| 32-bit word       | LDA            | STL             | LDAEX                    | STLEX                     |
| 16-bit halfword   | LDAH           | STLH            | LDAEXH                   | STLEXH                    |
| 8-bit byte        | LDAB           | STLB            | LDAEXB                   | STLEXB                    |
| 64-bit doubleword | -              | -               | LDAEXD                   | STLEXD                    |