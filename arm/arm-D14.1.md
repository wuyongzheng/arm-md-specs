## D14.1 Definitions

The following subsections give more information about terms used in the event definitions:

- Definition of terms.
- Levels of caches and TLBs.
- Counting events from shared components.
- Tracking the Guarded Control Stack data accesses.
- Counting exceptions taken locally or not taken locally.

## D14.1.1 Definition of terms

This section describes terms used by PMU events as they relate to the implementation of the PMU. For more definitions, see Glossary.

## Architectural event

An architectural event is an event which gives the same result for the same program on any implementation of the Arm architecture, subject to the program having the same inputs, including asynchronous events triggered by the system, any IMPLEMENTATION DEFINED or UNPREDICTABLE variation permitted by the event definition, and the reasonable degree of inaccuracy described in A reasonable degree of inaccuracy. INST\_RETIRED is an example of an architectural event.

An architectural event should not be confused with an event defined by the architecture, which is referred to as a Common event.

Note: Do not confuse Architectural events and Common events. An Architectural event can be either Common or IMPLEMENTATION DEFINED. See also Common event and IMPLEMENTATION DEFINED event.

## At-retirement event

An at-retirement event is generated by an Architecturally executed instruction that does not generate an exception, unless specified otherwise. This includes SVC, HVC, and SMC exceptions.

For cache and TLB events:

- The event counts each architecturally-executed instruction that generates the event.
- The event is only counted once, by the first instruction that causes it. This might not be the first instruction in program order.

Note

Consider two loads that execute out of order that access the same cache line granule which is not in the cache. The second instruction in program order causes the miss, and the first instruction fetches data from the same cache miss result. Only the second instruction counts the cache miss event. Also, the second instruction might be speculative and the first instruction retired, meaning the cache miss is not counted at all.

- The population counts for the events are the architecturally-executed instruction counts.

An event that is defined by the Performance Monitors Extension. For more information, see Common event numbers.

Note: Do not confuse Common events and Architectural events. A Common event can be either Architectural or Microarchitectural. See also Architectural event and Microarchitectural event.

Container size, in bits, that corresponds to the largest non-overlapping SVE or Advanced SIMD vector element size or scalar register size that is encoded in the instruction opcode. This excludes the 64-bit elements of the wide element variants of the SVE bitwise shift and integer compare instructions that overlap the narrower source and destination elements.

## Common event

## CSIZE

## Event in progress

Some events count when another event or condition is in progress . This might mean that the event counts the occupancy of a queue or other microarchitectural structure tracking the event. It is usually IMPLEMENTATION DEFINED when an event is in progress.

For example, the MEM\_ACCESS\_RD\_PERCYC event counts when the MEM\_ACCESS\_RD event is in progress, meaning on each Processor cycle, the counter increments by the number of Memory-read operations that are in progress.

These events can be used to calculate the average number of events in progress. In the case of the MEM\_ACCESS\_RD\_PERCYC event, this is also the average read latency. However, the definition of in progress might not include all parts of the operation.

Example D14-1

Stages of an operation not included in the definition of event in progress

In an example implementation, a Memory-read operation generated by a load instruction occupies three pipeline stages in the PE before generating a MEM\_ACCESS\_RD event when the PE starts to access memory. The event is then considered to be in progress until the data is returned to the PE. In the case of a Normal Cacheable access, the PE first looks in the Level 1 data cache, and if the address is cached, returns data in two cycles. Once the data is returned, it is another cycle before the result can be forwarded to any other instruction.

In this example, if all loads hit in the Level 1 cache, the average read latency calculated using the MEM\_ACCESS\_RD\_PERCYC and MEM\_ACCESS\_RD events might be two cycles. Although this value is correct for the IMPLEMENTATION SPECIFIC definition of this event, it has to be adjusted by a constant four additional cycles to match the more commonly understood definition of Level 1 cache access latency, which for this example would be quoted as six cycles.

## Instruction architecturally executed

An instruction that is part of the Execution stream. See also Architecturally executed.

Areasonable degree of inaccuracy allows for counts to be inaccurate in exceptional circumstances. For an event that counts instructions architecturally executed, this allows an implementation to count instructions that do not form part of the Execution stream because of an exceptional event, such as if the instruction generates a synchronous exception or entry to Debug state.

Instructions that have no visible effect on the architectural state of the PE are architecturally executed and counted even if they form part of the Execution stream.

Examples of instructions that have no visible effect are:

- A NOP .
- Aconditional instruction that fails its Condition code check.
- ACompare and Branch on Zero, CBZ , instruction that does not branch.
- ACompare and Branch on Nonzero, CBNZ , instruction that does not branch.

However, for events that count only the execution of instructions that update System registers, such as CID\_WRITE\_RETIRED, if such an instruction is executed twice without an intervening Context Synchronization event, it is constrained unpredictable whether the first instruction is counted.

## Instruction architecturally executed, Condition code check pass

Instruction architecturally executed, Condition code check pass is a class of events that explicitly do not occur for:

- Aconditional instruction that fails its Condition code check.
- ACompare and Branch on Zero, CBZ , instruction that does not branch.
- ACompare and Branch on Nonzero, CBNZ , instruction that does not branch.
- ATest and Branch on Zero, TBZ , instruction that does not branch.
- ATest and Branch on Nonzero, TBNZ , instruction that does not branch.

- AStore-Exclusive instruction that does not write to memory.

Otherwise, the definition of architecturally executed is the same as for Instruction architecturally executed.

Abranch that is architecturally executed, with condition code check pass is also described as a branch taken.

## Instruction memory access

APEacquires instructions for execution through instruction fetches. Instruction fetches might be due to:

- Fetching instructions that are architecturally executed.
- The result of the execution of an instruction prefetch instruction, PLI .
- Speculation that a particular instruction might be executed in the future.

The relationship between the fetch of an individual instruction and an instruction memory access is IMPLEMENTATION DEFINED. For example, an implementation might fetch many instructions including a non-integer number of instructions in a single instruction memory access.

## IMPLEMENTATIONDEFINEDevent

An event that is defined by the implementation. For more information, see IMPLEMENTATION DEFINED event numbers.

Note: Do not confuse IMPLEMENTATION DEFINED events and Microarchitectural events. An IMPLEMENTATION DEFINED event can be either Architectural or Microarchitectural. See also Architectural event and Microarchitectural event.

## Memory-read operations

APEaccesses memory through memory-read operations and Memory-write operations. A memory-read operation might be due to:

- The result of an architecturally executed Memory-reading instructions.
- The result of a Speculatively executed memory-reading instructions.
- Atranslation table walk.
- AGCSdata read operation.

Note

A GCS data read operation is considered a memory-read operation regardless of whether L1GCS\_CACHE event is implemented.

For levels of cache hierarchy beyond the Level 1 caches, memory-read operations also include accesses made as part of a refill of another cache closer to the PE. Such refills might be due to:

- Memory-read operations or Memory-write operations that miss in the cache
- The execution of a data prefetch instruction.
- The execution of a cache maintenance instruction.

Note

A prefetch instruction or cache maintenance instruction is not, in itself, an access to that cache. However, it might generate cache refills which are then treated as memory-read operations beyond that cache.

- Speculation that a future instruction might access the memory location.
- Instruction memory accesses to a unified cache, when the cache does not implement the L&lt;n&gt;I\_CACHE event.

This list is not exhaustive.

The relationship between memory-read instructions and memory-read operations is IMPLEMENTATION DEFINED. For example, for some implementations an LDP instruction that reads two 64-bit registers might generate one memory-read operation if the address is quadword-aligned, but for other addresses it generates two or more memory-read operations.

## Memory-reading instructions

An instruction with explicit Memory read effects, including Tag-read effects. Loads and atomic instructions that return a value to the PE are counted as Memory-reading instructions. MRS and MRRS instructions transformed to memory reads by FEAT\_NV2 are counted as Memory-reading instructions.

Unless otherwise specified, this includes instructions that can have a Memory read effect, even if the instruction does not actually read from memory for some other reason. For example, a conditional load in AArch32 state that fails its condition code, an SVE predicated load with inactive predicates, or a load that generates an MMU fault.

It is IMPLEMENTATION DEFINED whether the prefetch instructions PRFM , PLD , PLDW , and PLI count as integer data-processing instructions or Memory-reading instructions. Arm recommends that if the instruction is not implemented as a NOP then it is counted as a Memory-reading instruction.

Memory-writing instructions, other than atomics, that return a result in a PE register other than data from the location being accessed are not counted as Memory-reading instructions. This includes Store-exclusive, ST64BV , and ST64BV0 .

Atomic instructions that do not return a value to the PE are not counted as Memory-reading instructions.

Instructions with only a Tag-Check-read effect are not counted as Memory-reading instructions.

## Memory-write operations

Memory-write operations might be due to:

- The result of an architecturally executed Memory-writing instructions.
- The result of a Speculatively executed Memory-writing instructions.
- Ahardware update of a translation table entry.
- AGCSdata write operation.

Note

A GCS data write operation is considered a Memory-write operation regardless of whether L1GCS\_CACHE event is implemented.

Note

Speculatively executed Memory-writing instructions that do not become architecturally executed must not alter the architecturally defined view of memory. They can, however, generate a Memory-write operation that is later undone in some IMPLEMENTATION SPECIFIC way.

For levels of cache hierarchy beyond the Level 1 caches, Memory-write operations also include accesses made as part of a write-back from another cache closer to the PE. Such write-backs might be due to:

- Evicting a dirty line from the cache, to allocate a cache line for a cache refill, see Memory-read operations.
- The execution of a cache maintenance instruction.

Note

A cache maintenance instruction is not in itself an access to that cache. However, it might generate write-backs which are then treated as Memory-write operations beyond that cache.

- The result of a coherency request from another PE.

This list is not exhaustive.

DC ZVA is counted as a Memory-write operation. ST64BV and ST64BV0 are Store with status result instructions, but for the purpose of the PMU they are treated as Memory-write operations.

The relationship between Memory-writing instructions and Memory-write operations is IMPLEMENTATION DEFINED. For example, for some implementations an STP instruction that writes two 64-bit registers might generate one Memory-write operation if the address is quadword-aligned, but for other addresses it generates two or more Memory-write operations. In some implementations, the

## MSIZE

Memory element access size, in bits, that corresponds to a load or store instruction mnemonic suffix, where B=8, H=16, W=32 and D=64. When an instruction mnemonic does not end with B, H, W or D, the memory access size is implied by the scalar transfer register size or SIMD transfer register element size.

## Non-SIMD SVE and SME instructions

These instructions are:

- Scalar vector length calculation instructions, ADDPL, ADDSPL, ADDSVL, ADDVL, RDSVL, and RDVL.
- Scalar predicate count instructions that determine a number of elements implied by a named predicate constraint, and use that value to calculate a result written to a general-purpose register. See Predicate count for more information.
- Compare and terminate instructions, CTERMEQ, CTERMNE.
- MRS and MSR instructions for accessing SVE and SME Special-purpose and System registers, including SMSTART and SMSTOP.

An instruction might create one or more microarchitectural operations (µ-ops) at any point in the execution pipeline. Depending on the event definition, the µ-ops might be counted instead of instructions. The definition of a µ-op is IMPLEMENTATION SPECIFIC. An architecture instruction might create more than one µ-op for each instruction. µ-ops might also be removed or merged in the execution stream, so an architecture instruction might create no µ-ops for an instruction. Any arbitrary translation of instructions to an equivalent sequence of µ-ops is permitted.

## Operation

result of two STR instructions that write to adjacent memory might be merged into a single Memory-write operation.

Note

The data written back from a cache that is shared with other PEs might not be data that was written by the PE that performs the operation that leads to the write-back. Nevertheless, the event is counted as a write-back event for that PE.

## Memory-writing instructions

Are instructions with explicit Memory write effects, including Tag-write effects. Stores and atomic instructions are counted as Memory-writing instructions.

Unless otherwise specified, this includes instructions that can have a Memory write effect, even if the instruction does not actually write to memory for some other reason. For example, a conditional store in AArch32 state that fails its condition code, an SVE predicated store with inactive predicates, a CAS or Store-exclusive that does not update memory, or a store that generates an MMU fault.

DC ZVA , DC GVA , and DC GZVA are counted as Memory-writing instructions. MSR and MSRR instructions transformed to memory writes by FEAT\_NV2 are counted as Memory-writing instructions.

## Microarchitectural event

Amicroarchitectural event is any event which is not architectural. That is, it will give different results for the same program on two different implementations of the Arm architecture, due to microarchitectural differences in the implementations. L1D\_CACHE\_REFILL is an example of a microarchitectural event.

Amicroarchitectural event should not be confused with an event defined by the implementation, which is referred to as an IMPLEMENTATION DEFINED event.

Note: Do not confuse Microarchitectural events and IMPLEMENTAION DEFINED events. A Microarchitectural event can be either Common or IMPLEMENTATION DEFINED. See also Common event and IMPLEMENTATION DEFINED event.

## Processor cycle

For a non-multithreaded implementation, this means a cycle of the processor. For a multithreaded implementation, processor cycle means each cycle of the multithreaded processor, not just those cycles for which the PE counting the event is active.

## SIMD SVE and SME instructions

These instructions are:

- Instructions operating on one-dimensional vectors, reading from or writing to SVE scalable vector registers, SVE scalable predicate registers, or SME ZA array vector slices.

This means the relationship between a µ-op and an architecturally executed instruction is IMPLEMENTATION DEFINED.

Note

The architecture does not require that an implementation that generates µ-ops must count µ-ops for operations. An implementation can choose to interpret operation as instruction.

The counting of operations can indicate the workload on the PE. However, there is no requirement for operations to represent similar amounts of work, and direct comparisons between different microarchitectures are not meaningful.

Operations might be defined with reference to a particular instruction or type of instruction. In the case of operations this means operations with semantics that map to that type of instruction.

For example, an implementation splits an A32 or T32 LDM instruction of six registers into six µ-ops, one for each load, and a seventh address-generation operation to determine the base address or writeback address. Also, for doubleword alignment, the six load µ-ops might combine into four operations, that is, a word load, two doubleword loads, and a second word load. This single instruction can then be counted as five, or possibly six, events:

- Four (Operation speculatively executed - Load) events.
- One (Operation speculatively executed - Integer data processing) event.
- One (Operation speculatively executed - Software change of the PC) event if the PC was one of the six registers in the LDM instruction.

## Operation speculatively executed

An Operation that is Speculatively executed.

There is no architecturally guaranteed relationship between a Speculatively executed micro-op and an architecturally executed instruction.

The results of such an operation can also be discarded, if it transpires that the operation was not required, such as following a mispredicted branch. Therefore, the architecture defines these events as operations speculatively executed , where appropriate.

Many PMU events count operations that are speculatively executed. This means that the PMU can observe and record the behavior of operations executed under the effects of speculation. However, the PMUmust not count an event that might be used to infer values that cannot be accessed or used by the operation, as defined by Restrictions on the effects of speculation.

## For example:

- An address that is not permitted to be used by the operation might be inferred by whether it is present in a cache or TLB.
- Acondition code that is not permitted to be used by the operation can be inferred by whether a branch was taken or not taken.
- Apredicate value that is not permitted to be used by the operation can be inferred by whether a predicate value is empty or not.

Note

In some events, operation has a more specific meaning described in the event. See SIMD SVE and SME instructions.

## Slot

- Instructions operating on two-dimensional tiles, reading from or writing to SME ZA tiles.

Data processing instructions operating on one dimensional scalable vectors are counted by counters counting FP*\_SCALE\_OPS\_SPEC and INT\_SCALE\_OPS\_SPEC events, and increment the counter by a value v such that ( v × (VL÷128)) is the number of arithmetic operations carried out by the operation or instruction which causes the counter to increment.

Load and store instructions operating on scalable vectors or the ZA array are counted by counters counting (LDST|LD|ST)\_SCALE\_OPS\_SPEC and (LDST|LD|ST)\_SCALE\_BYTES\_SPEC events, and increment the counter by a value v such that:

- For the *\_OPS\_SPEC events, ( v × (VL÷128)) is number of vector elements loaded or stored by the operation or instruction which causes the counter to increment. That is, v is (128÷CSIZE), multiplied by the number of transferred registers.
- For the *\_BYTES\_SPEC events, ( v × (VL÷128)) is number of bytes loaded or stored by the operation or instruction which causes the counter to increment. That is, v is (16÷(CSIZE÷MSIZE)), multiplied by the number of transferred registers.

This does not include load instructions which load a single element and replicate it across a one dimensional scalable vector.

Data processing instructions operating on two dimensional scalable tiles are counted by counters counting *\_SCALE2\_OPS\_SPEC events, and increment the counter by a value v such that ( v × (VL÷128) 2 ) is the number of arithmetic operations carried out by the operation or instruction which causes the counter to increment.

Note

Animplementation might increment the counter once by v for the whole instruction, or, if the instruction is executed as a sequence of µ-ops multiple times by some fraction of v for each µ-op, such that it increments by v in total.

In addition all of the following apply:

- Events of the form &lt;TYPE&gt;\_SCALE{2}\_OPS\_SPEC will increment a counter by v only if the instruction performs computations on a structure with elements of type &lt;TYPE&gt;.
- Events of the form &lt;TYPE&gt;\_&lt;PRECISION&gt;\_SCALE{2}\_OPS\_SPEC will increment a counter by v only if the largest precision operand of type &lt;TYPE&gt; read or written by the instruction is &lt;PRECISION&gt;.
- Events of the form &lt;TYPE&gt;\_&lt;PRECISION&gt;\_SCALE{2}\_MIN\_OPS\_SPEC will increment a counter by v only if the smallest precision operand of type &lt;TYPE&gt; read or written by the instruction is &lt;PRECISION&gt;.

An implementation of a PE might be able to execute multiple micro-ops in a single processor cycle. The maximum number of micro-ops that can be executed might vary at different points in the execution pipeline.

To allow profiling of the utilization of the resource of the PE, an IMPLEMENTATION SPECIFIC point in the execution pipeline is chosen where the maximum number of micro-ops that can be executed is an IMPLEMENTATION DEFINED fixed value.

Each possible micro-op that can be executed at that point in a cycle is called a Slot. The maximum number of micro-ops that can be executed is defined by PMMIR.SLOTS.

## Software change of the PC

All of the following are treated as a software change of the PC:

- Branch instructions.
- Memory-reading instructions that explicitly write to the PC.
- Data-processing instructions that explicitly write to the PC.
- Exception return instructions.

It is IMPLEMENTATION DEFINED whether any or all of the following are treated as software changes of the PC:

## Taken locally

VL

- BRK and BKPT instructions.
- An exception generated because an instruction is UNDEFINED.
- The exception-generating instructions, SVC , HVC , and SMC .
- Context synchronization barrier ISB instructions.

## Speculatively executed

An instruction or operation that is counted by an event when it might be Speculative.

The architecture does not define the point in a pipeline where an event is counted. For some events, this means the operation or instruction is counted when the operation or instruction is Speculative. The results of such an operation or instruction might later be discarded, if it transpires that the operation was not required, such as following a mispredicted branch, or might be later resolved to be Architecturally executed.

Different groups of events might be counted at different points in the pipeline and so can have different IMPLEMENTATION DEFINED definitions of speculatively executed. Such groups share a common base type, which the event name denotes. Each of the events in the previous example is of the base type, operation speculatively executed.

For groups of events with a common base type, speculatively executed operations are all counted on the same basis, which normally means at the same point in the pipeline. It is possible to compare the counts and make meaningful observations about the program being profiled.

Taken locally is a qualifier that determines which instances of an exception are counted by particular PMUevents. See Counting exceptions taken locally or not taken locally.

In this context, an exception that is Taken locally means an exception that is one of:

- Taken to the current Exception level.

Note

This is not possible when the current Exception level is EL0.

- Taken from EL0 to EL1.

- Taken from EL0 to EL2 because the Effective value of HCR\_EL2.{E2H, TGE} is {1, 1}.

Note

An exception taken from EL0 to EL2 because the Effective value of HCR\_EL2.{E2H, TGE} is {0, 1} is not Taken locally . This includes exceptions taken to EL2 using AArch32 when HCR.TGE is 1.

The current SVE vector length, in bits.

## D14.1.2 Levels of caches and TLBs

The mapping of levels of cache and TLB to the PMU events is IMPLEMENTATION DEFINED. Although CLIDR\_EL1 and CLIDR define the implemented levels of cache, these are not required to correspond with the levels of cache defined for PMUevents. The architecture does not provide any way of determining implemented levels of TLB. Also, many implementations include structures that provide some caching at a higher level than the level 1 caches or TLBs. Typically, these structures, that might be called Level 0 caches, or mini caches, or microcaches, are invisible to software. The IMPLEMENTATION SPECIFIC nature of cache and TLB implementations mean that, in general, PMU event counts cannot be used reliably to make direct comparisons between different implementations, and Arm recommends the following implementation guidelines:

- If L3D\_CACHE events are implemented, then L2D\_CACHE and if applicable L2I\_CACHE events should be implemented.
- If L2D\_CACHE events are implemented, then L1D\_CACHE and if applicable L1I\_CACHE events should be implemented.

- If L2I\_CACHE events are implemented, then L1I\_CACHE events should be implemented.
- Where the Last Level of cache is also the Level 3 or Level 2 unified cache, the LL\_CACHE events should be implemented in preference to the L3D\_CACHE or L2D\_CACHE events as applicable.
- For the Level &lt;n&gt; cache, where &lt;n&gt; = 1 or &lt;n&gt; = 2:
- -If the Level &lt;n&gt; cache is unified, but the cache can disambiguate between Data and Instruction accesses to the cache, then both the L&lt;n&gt;D\_CACHE and L&lt;n&gt;I\_CACHE events should be implemented.
- -If the cache is unified and the cache cannot disambiguate between Data and Instruction accesses, then only the L&lt;n&gt;D\_CACHE should be implemented, counting all accesses.

This final property is IMPLEMENTATION DEFINED.

If an implementation uses separate caching structures to cache the GCS data and translations, the implementation might be capable of separately tracking the Guarded Control Stack data accesses and their translations in the caches and TLBs. See Tracking the Guarded Control Stack data accesses for more information.

N1\_*, N2\_*, N3\_*, and N4\_* events are defined for identifying the non-uniform memory access (NUMA) distance for data returned directly from caches and memory, with support for:

- Up to four NUMA distance levels.
- Up to three cache types at each level.
- Up to three memory types at each level.
- Cache snoop responses at each level.

The NUMA distance indicates the relative distance that the return data has traveled. The NUMA distance is a relative distance that is defined at the system level, allowing flexibility of use for different systems that may have different levels of hierarchy. The interpretation of NUMA distance is IMPLEMENTATION DEFINED, and should be the same for all PEs in the base system.

The mapping of NUMA distance values to LOCAL and REMOTE events is IMPLEMENTATION DEFINED.

The definition of memory types in the system is IMPLEMENTATION DEFINED, but must be broadly similar for all devices in the system.

## D14.1.3 Counting events from shared components

There is no architectural concept of a shared component. However, when a cache, a bus, or any other system component that might generate countable events is implemented, and:

- The extent of the first-order effects due to an event from that component are only applicable to a single PE, then the event is not shared.
- Otherwise, the event is shared.

Second-order effects are not considered when determining if an event is shared.

If the cache is shared and the Effective value of PMEVTYPER&lt;n&gt;\_EL0.MT for the counter is 0b0 , then the counter counts only events Attributable to the PE counting the event. For a multithreaded processor implementation, if the cache is shared by PEs other than the PEs in the multithreaded processor and the Effective value of PMEVTYPER&lt;n&gt;\_EL0.MT for the counter is 0b1 , the counter counts only events Attributable to PEs in the multithreaded processor. In all other cases, it is IMPLEMENTATION DEFINED whether only events Attributable to the PE counting the event or all events are counted and might depend on the Effective value of PMEVTYPER&lt;n&gt;\_EL0.MT.

If an implementation uses shared caching structures for GCS data and translations, the implementation might be capable of separately tracking the Guarded Control Stack data accesses and their translations in the caches and TLBs. See Tracking the Guarded Control Stack data accesses for more information.

Example D14-2 First and second order effects of a cache miss in a multiple-PE implementation

In an implementation that consists of two PEs, each with its own L1 cache, a cache miss by one of the PEs is a first-order effect of an access to its cache. Any snoop that is performed on the L1 cache of the other PE in the implementation as a result of that cache miss is a second order effect.

Note

Shared events are inherently linked to microarchitectures and so the implementer must make an informed decision about how such events are implemented.

## D14.1.4 Tracking the Guarded Control Stack data accesses

All of the following PMU events are GCS PMU events:

- L1GCS*.
- GCSTLB*.
- STALL\_*\_GCS*.

If an implementation is capable of separately tracking the Guarded Control Stack data accesses and their translations in the caches and TLBs, all of the following apply:

- The GCS PMU events are permitted to be implemented and allow software to disambiguate the performance aspects of Guarded Control Stack data accesses from other data accesses.
- L1GCS\_CACHE* events and L1GCS\_TLB* events are generated for Guarded Control Stack data accesses.
- L1D\_CACHE* events and L1D\_TLB* events are not generated for Guarded Control Stack data accesses.

If an implementation is not capable of separately tracking the Guarded Control Stack data accesses and their translations in the caches and TLBs, all of the following apply:

- The GCS PMU events are not implemented, and software is not permitted to disambiguate the performance aspects of Guarded Control Stack data accesses from other data accesses.
- L1GCS\_CACHE* events and L1GCS\_TLB* are not generated for Guarded Control Stack data accesses.
- L1D\_CACHE* events and L1D\_TLB* events are generated for Guarded Control Stack data accesses.

## D14.1.5 Counting exceptions taken locally or not taken locally

Table D14-1 shows the events for exceptions taken to an Exception level using AArch64.

Table D14-1 Events for exceptions taken to an Exception level using AArch64

| ESR.EC   | Description                                                | Event number and classification for exceptions   | Event number and classification for exceptions   |
|----------|------------------------------------------------------------|--------------------------------------------------|--------------------------------------------------|
| ESR.EC   | Description                                                | Taken locally                                    | Not Taken locally                                |
| 0x00     | Unknown or uncategorized                                   | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
| 0x01     | WF* traps                                                  | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
| 0x03     | AArch32 MCR / MRC traps on ( coproc == 0b1111 ) accesses   | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
| 0x04     | AArch32 MCRR / MRRC traps on ( coproc == 0b1111 ) accesses | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
| 0x05     | AArch32 MCR / MRC traps on ( coproc == 0b1110 ) accesses   | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
| 0x06     | AArch32 LDC / STC traps on ( coproc == 0b1110 ) accesses   | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
| 0x07     | Advanced SIMD or FP traps                                  | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
| 0x08     | AArch32 MVFR*and FPSID traps                               | -                                                | 0x008D , EXC_TRAP_OTHER                          |

| ESR.EC   | Description                                                |                           | Event number and classification for exceptions   | Event number and classification for exceptions   |
|----------|------------------------------------------------------------|---------------------------|--------------------------------------------------|--------------------------------------------------|
| ESR.EC   |                                                            |                           | Taken locally                                    | Not Taken locally                                |
| 0x0C     | AArch32 MCRR / MRRC traps on ( coproc == 0b1110 ) accesses |                           | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
| 0x0E     | Illegal instruction set state                              |                           | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
| 0x11     | AArch32 SVC                                                |                           | 0x0082 , EXC_SVC                                 | 0x008D , EXC_TRAP_OTHER                          |
| 0x12     | AArch32 HVC that is not disabled                           |                           | -                                                | 0x008A , EXC_HVC                                 |
| 0x13     | AArch32 SMC that is not disabled                           | to EL2                    | -                                                | 0x008D , EXC_TRAP_OTHER                          |
|          |                                                            | to EL3                    | -                                                | 0x0088 , EXC_SMC                                 |
| 0x15     | AArch64 SVC                                                |                           | 0x0082 , EXC_SVC                                 | 0x008D , EXC_TRAP_OTHER                          |
| 0x16     | AArch64 HVC that is not disabled                           |                           | 0x008A , EXC_HVC                                 | 0x008A , EXC_HVC                                 |
| 0x17     | AArch64 SMC that is not disabled                           | to EL2                    | -                                                | 0x008D , EXC_TRAP_OTHER                          |
|          |                                                            | to EL3                    | 0x0088 , EXC_SMC                                 | 0x0088 , EXC_SMC                                 |
| 0x18     | AArch64 MSR , MRS and System instruction traps             |                           | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
| 0x19     | SVE traps                                                  |                           | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
| 0x1E     | Granule Protection Check exception                         | Inst                      | 0x0083 , EXC_PABORT                              | 0x008B , EXC_TRAP_PABORT                         |
|          |                                                            | Data                      | 0x0084 , EXC_DABORT                              | 0x008C , EXC_TRAP_DABORT                         |
| 0x1F     | IMPLEMENTATION DEFINED exception taken to EL3              |                           | IMPLEMENTATION DEFINED a                         | IMPLEMENTATION DEFINED a                         |
| 0x20     | Instruction Abort from below                               |                           | 0x0083 , EXC_PABORT                              | 0x008B , EXC_TRAP_PABORT                         |
| 0x21     | Instruction Abort from current Exception level             |                           | 0x0083 , EXC_PABORT                              | -                                                |
| 0x22     | PC alignment                                               |                           | 0x0083 , EXC_PABORT                              | 0x008B , EXC_TRAP_PABORT                         |
| 0x24     | Data Abort from below                                      |                           | 0x0084 , EXC_DABORT                              | 0x008C , EXC_TRAP_DABORT                         |
| 0x25     | Data Abort from current Exception level                    |                           | 0x0084 , EXC_DABORT                              | -                                                |
| 0x26     | SP alignment fault exception                               |                           | 0x0084 , EXC_DABORT                              | 0x008C , EXC_TRAP_DABORT                         |
| 0x28     | AArch32 FP exception                                       |                           | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
| 0x2C     | AArch64 FP exception                                       |                           | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
| 0x2D     | GCS Exception                                              | GCS Data Check exception  | 0x0084 , EXC_DABORT                              | 0x008C , EXC_TRAP_DABORT                         |
|          |                                                            | EXLOCK exception          | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
|          |                                                            | Trap on GCSSTR or GCSSTTR | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |
| 0x2F     | SError exception                                           |                           | 0x0084 , EXC_DABORT                              | 0x008C , EXC_TRAP_DABORT                         |

| ESR.EC           | Description                                | Event number and classification for exceptions   | Event number and classification for exceptions   |
|------------------|--------------------------------------------|--------------------------------------------------|--------------------------------------------------|
| ESR.EC           | Description                                | Taken locally                                    | Not Taken locally                                |
| 0x30             | Breakpoint from below                      | 0x0083 , EXC_PABORT                              | 0x008B , EXC_TRAP_PABORT                         |
| 0x31             | Breakpoint from current Exception level    | 0x0083 , EXC_PABORT                              | -                                                |
| 0x32             | Software step from below                   | 0x0083 , EXC_PABORT                              | 0x008B , EXC_TRAP_PABORT                         |
| 0x33             | Software step from current Exception level | 0x0083 , EXC_PABORT                              | -                                                |
| 0x34             | Watchpoint from below                      | 0x0084 , EXC_DABORT                              | 0x008C , EXC_TRAP_DABORT                         |
| 0x35             | Watchpoint from current Exception level    | 0x0084 , EXC_DABORT                              | -                                                |
| 0x38             | AArch32 BKPT instruction                   | 0x0083 , EXC_PABORT                              | 0x008B , EXC_TRAP_PABORT                         |
| 0x3A             | AArch32 Vector Catch debug event           | 0x0083 , EXC_PABORT                              | 0x008B , EXC_TRAP_PABORT                         |
| 0x3C             | AArch64 BRK instruction                    | 0x0083 , EXC_PABORT                              | 0x008B , EXC_TRAP_PABORT                         |
| -                | IRQ interrupt                              | 0x0086 , EXC_IRQ                                 | 0x008E , EXC_TRAP_FIQ                            |
| -                | FIQ interrupt                              | 0x0087 , EXC_FIQ                                 | 0x008F , EXC_TRAP_FIQ                            |
| All other values | All other exceptions                       | 0x0081 , EXC_UNDEF                               | 0x008D , EXC_TRAP_OTHER                          |

Note

The Glossary defines the term Taken locally, that is used in event definitions in Common microarchitectural events. See also Exception levels for more information.